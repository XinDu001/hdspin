# hdspin sandbox input file template
# Make your own with the name `config.yaml` in the working directory
# Matthew R. Carbone & Marco Baity-Jesi


# Run parameters --------------------------------------------------------------
# -----------------------------------------------------------------------------


# Runs all permutations of the specified parameters. Note one can move
# the parameters between `permute_over` and `no_permute_over` seamlessly, but
# the values in `permute_over` must be lists (even lists of one object); the
# values in `no_permute_over` must be values.
permute_over:

    # The log10 number of timesteps of the standard simulation/
    # approximate maximum simulation time for the Gillespie simulation. 
    # Note that in the case of Gillespie, the simulation is guaranteed to 
    # reach at least this value.
    log10_timesteps: [6]

    # Total number of tracers to simulate, per MPI task. Each tracer will have
    # its own randomly initialized energy landscape.
    n_tracers: [100]

    # Total number of tracers to simulate. Each tracer will have its
    # own randomly initialized energy landscape.
    n_spins: [20]

    # Sets the dynamics of the simulation.
    # Options are: {standard, standard-loop, gillespie}
    dynamics: [standard]

    # Sets the energy landscape of the simulation
    # Options are: {erem, rem}
    landscape: [erem]

    # Sets the temperature, can use either beta (1/T) or T itself
    beta: [2.0]
    # temperature: 0.5

no_permute_over:

    # Sets the critical inverse temperature of the simulation. If null (None)
    # this will default to 1.0 for EREM and 1.177410022515475 for REM.
    # Note that the latter is ~sqrt(2 log 2).
    beta_c: null


# -----------------------------------------------------------------------------

# Sets the aging function parameter dw
# NOTE: this should not in general be changed from default (null) which
# will be 0.5
aging_dw: null


# Set the number of grid points for the energy and aging function grids.
energy_gridpoints: 100
pi_gridpoints: 100



# Set the SLURM config information - this is only accessed in the execute
# step. The SLURM submission scripts are written right before submitting to the
# job controller
SLURM:
    partition: Old
    time: null
    account: null
    constraint: null
    N_nodes: 2
    tasks_per_node: 24
    # total_cpus: 96
    # mem_per_cpu: 2500
    mem_per_node: 62  # GB
    other_lines: ['module load compilers/gcc-10.1.0']

    # Architecture-specific
    cores_per_node: 24
    hyperthreads_per_core: 1
    # max_threads: 2



# #!/bin/bash
# #SBATCH -N 1
# #SBATCH -c 1
# #SBATCH -p New
# #SBATCH --mem=2GB
# #SBATCH --output=job_data/rem.%A.out
# #SBATCH --error=job_data/rem.%A.err
# #SBATCH --job-name=rem

# # export OMP_NUM_THREADS=1
# # export USE_SIMPLE_THREADED_LEVEL3=1

# #export PATH="/opt/pb/gcc-10.1.0/bin:$PATH"
# #export LD_LIBRARY_PATH="/opt/pb/gcc-10.1.0/lib:/opt/pb/gcc-10.1.0/lib64:$LD_LIBRARY_PATH"

# module load compilers/gcc-10.1.0
# ./main.o "$@"
